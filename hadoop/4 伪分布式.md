# 伪分布式运行

Pseudo-Distributed Operation伪分布式运行，指的是将所有hadoop中的节点都运行在一台主机上，比如namenode和datanode都运行在一台主机环境上，适合学习使用，简单了解。

## 启动HDFS伪分布式运行

### 配置 etc/hadoop/hadoop-env.sh

```bash
vim  etc/hadoop/hadoop-env.sh
//---------
export JAVA_HOME=/usr/java/latest //配置javahome地址
```

### 配置etc/hadoop/core-site.xml:

```xml
<configuration>
    <!--指定HDFS中NameNode的地址-->
    <property>
        <name>fs.defaultFS</name>
        <value>hdfs://hadoop101:9000</value>
        <!--value值配置主机域名或者ip地址-->
    </property>
    <!--指定hadoop运行时产生文件的存储目录-->
    <property>
        <name>hadoop.tmp.dir</name>
        <value>/opt/module/hadoop-2.9.2/data/tmp</value>
        <!--value值配置主机域名或者ip地址-->
    </property>
</configuration>
```

### 配置etc/hadoop/hdfs-site.xml:

```xml
<configuration>
    <!--配置副本数量，由于我们只有一台主机，所以只配置一个副本-->
    <property>
        <name>dfs.replication</name>
        <value>1</value>
    </property>
</configuration>
```

### 配置ssh连接本地

由于伪分布式中，各个节点之间的通讯是基于ssh，实际上就是连接本地localhost，如果不想要通过ssh密码的方式互相连接，那么就需要进行ssh的间的密钥配置

```bash
ssh-keygen -t rsa -P '' -f ~/.ssh/id_rsa
cat ~/.ssh/id_rsa.pub >> ~/.ssh/authorized_keys
chmod 0600 ~/.ssh/authorized_keys
```

### 格式化hdfs

初始化启动hdfs之前，就要像硬盘格式化一样，对hdfs进行格式化，但是务必注意，一旦namenode启动后，就不能再进行格式化了，否则datanode将找不到自己的namenode，就好比换大哥了小弟不知道

```bash
bin/hdfs namenode -format
```

### 启动namenode和datanode

```bash
sbin/hadoop-daemon.sh start namenode
sbin/hadoop-daemon.sh start datanode
```

### 访问namenode web服务

浏览器打开 hadoop101:50070

### 创建HDFS下的目录以供执行mapreduce

```bash
  $ bin/hdfs dfs -mkdir /user
  $ bin/hdfs dfs -mkdir /user/<username>
```

### 将本地input拷贝至hdfs

```bash
$ bin/hdfs dfs -put etc/hadoop input
```

### 运行示例代码

```bash
$ bin/hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-2.9.2.jar grep input output 'dfs[a-z.]+'
```

 检查运行结果

```bash
$ bin/hdfs dfs -cat output/*
```

### 关闭namenode和datanode

```bash
sbin/hadoop-daemon.sh stop namenode
sbin/hadoop-daemon.sh stop datanode
```



## 启动yarn并运行mapreduce程序

### 配置yarn-env.sh

```bash
export JAVA_HOME=/usr/lib/jvm/java-1.8.0-openjdk.x86_64
```

### 配置:`etc/hadoop/mapred-site.xml`:

> 此文件不存在需要复制mapred-site.xml.template获得

```xml
<configuration>
    <property>
        <name>mapreduce.framework.name</name>
        <value>yarn</value>
    </property>
</configuration>
```

### 配置etc/hadoop/yarn-site.xml

```xml
<configuration>
    <property>
        <name>yarn.nodemanager.aux-services</name>
        <value>mapreduce_shuffle</value>
    </property>
</configuration>
```

### 启动yarn

```bash
$ sbin/start-yarn.sh
```

### 访问ResourceManager web服务

浏览器访问http://localhost:8088/

### 运行mapreduce同hdfs部分

### 停止yarn和hdfs

```bash
sbin/stop-dfs.sh
sbin/stop-yarn.sh
```

